{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d644763f-6b00-4864-9693-065f88e5129e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 404 Errors: 2\n"
     ]
    }
   ],
   "source": [
    "# 1 You are given a log file that records the status of a web server\n",
    "# at regular intervals. How would you write a function to extract and count the number of &quot;404 Not Found&quot; errors in the log file?\n",
    "\n",
    "def count_404_errors(log_filename):\n",
    "    \"\"\"Counts the number of '404 Not Found' errors in a log file.\"\"\"\n",
    "    count = 0\n",
    "    with open(log_filename, \"r\") as file:\n",
    "        for line in file:\n",
    "            if \"404 Not Found\" in line:  # Check if the line contains the error\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "log_file = \"server.log\"\n",
    "print(f\"Total 404 Errors: {count_404_errors(log_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c322671-b8a7-486b-b414-41ea0165c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Write a Python function that takes a CSV file containing customer orders (order ID, customer name, product, quantity,\n",
    "# price) and generates a new CSV file that contains only the orders where the total value (quantity * price) exceeds a certain threshold.\n",
    "\n",
    "import csv\n",
    "\n",
    "def filter_high_value_orders(input_file, output_file, threshold):\n",
    "    \"\"\"Filters orders where total value (quantity * price) exceeds the threshold.\"\"\"\n",
    "    with open(input_file, \"r\") as infile, open(output_file, \"w\", newline=\"\") as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "\n",
    "        header = next(reader)  # Read the header row\n",
    "        writer.writerow(header)  # Write the same header to the new file\n",
    "\n",
    "        for row in reader:\n",
    "            order_id, customer_name, product, quantity, price = row\n",
    "            if int(quantity) * float(price) > threshold:\n",
    "                writer.writerow(row)  # Write the row if it meets the condition\n",
    "\n",
    "filter_high_value_orders(\"orders.csv\", \"high_value_orders.csv\", 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e44df612-e6ae-48d2-a81c-89428fd258b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product\n",
      "Laptop       3200\n",
      "Monitor      1700\n",
      "Keyboard      700\n",
      "Mouse         450\n",
      "USB Cable     125\n",
      "Name: sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3 You are tasked with analyzing a large Excel file containing sales\n",
    "# data. How would you write a function that reads the Excel file and returns the top 5 products with the highest sales?\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def top_5_products(excel_file, sheet_name=\"Sheet1\"):\n",
    "    \"\"\"Reads an Excel file and returns the top 5 products with the highest sales.\"\"\"\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "    \n",
    "    # Ensure the column names are correct (assuming 'product' and 'sales' columns exist)\n",
    "    if \"product\" not in df.columns or \"sales\" not in df.columns:\n",
    "        raise ValueError(\"Excel file must contain 'product' and 'sales' columns.\")\n",
    "    \n",
    "    # Sort products by sales in descending order and get the top 5\n",
    "    top_products = df.groupby(\"product\")[\"sales\"].sum().nlargest(5)\n",
    "    \n",
    "    return top_products\n",
    "\n",
    "top_5 = top_5_products(\"sales_data.xlsx\")\n",
    "print(top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ffec972-ff95-4458-9501-35cf904c26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 You’re working with a function that checks if a list of integers is sorted in ascending order. How would you use assert to\n",
    "# validate that the function works as expected for different test cases?\n",
    "\n",
    "def is_sorted(lst):\n",
    "    \"\"\"Returns True if the list is sorted in ascending order, otherwise False.\"\"\"\n",
    "    return all(lst[i] <= lst[i+1] for i in range(len(lst) - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64a1e551-3964-4fd1-a5ec-688bc8e3857a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# Test cases\n",
    "assert is_sorted([1, 2, 3, 4, 5]) == True   # Sorted list\n",
    "assert is_sorted([5, 4, 3, 2, 1]) == False  # Descending order\n",
    "assert is_sorted([1, 1, 2, 2, 3]) == True   # Sorted with duplicates\n",
    "assert is_sorted([10]) == True              # Single element\n",
    "assert is_sorted([]) == True                # Empty list is considered sorted\n",
    "assert is_sorted([3, 2, 5, 4]) == False     # Unsorted list\n",
    "\n",
    "print(\"All test cases passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fd68f69-5a3f-478f-8f25-2fe01bd69290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Product  Sales        Sheet\n",
      "0     Laptop   1500  Electronics\n",
      "1      Mouse    200  Electronics\n",
      "2   Keyboard    300  Electronics\n",
      "3    Monitor    800  Accessories\n",
      "4  USB Cable     50  Accessories\n",
      "5    Printer    400  Accessories\n"
     ]
    }
   ],
   "source": [
    "# 5 Write a Python function that takes an Excel file with multiple sheets and merges all sheets into one large dataframe,\n",
    "# preserving the sheet names as a new column indicating the origin of the data.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def merge_sheets(excel_file):\n",
    "    \"\"\"Merges all sheets from an Excel file into one DataFrame, adding a column for sheet names.\"\"\"\n",
    "    all_sheets = pd.read_excel(excel_file, sheet_name=None)  # Read all sheets into a dictionary\n",
    "    merged_df = []\n",
    "\n",
    "    for sheet_name, df in all_sheets.items():\n",
    "        df[\"Sheet\"] = sheet_name  # Add sheet name as a new column\n",
    "        merged_df.append(df)\n",
    "\n",
    "    return pd.concat(merged_df, ignore_index=True)  # Combine all sheets\n",
    "\n",
    "merged_df = merge_sheets(\"multi_sheet_sales.xlsx\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdd6830b-9591-4ffd-8ca8-e0df9d4f51c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32.0, 59.0, 77.0, 86.0, 41.0]\n"
     ]
    }
   ],
   "source": [
    "# 6. Write a list comprehension that converts a list of temperature\n",
    "# values in Celsius to Fahrenheit, filtering out any temperatures that are below 0°C.\n",
    "\n",
    "\n",
    "\n",
    "celsius_temps = [-10, 0, 15, 25, -5, 30, 5]\n",
    "\n",
    "# Convert to Fahrenheit and filter out temperatures below 0°C\n",
    "fahrenheit_temps = [(temp * 9/5) + 32 for temp in celsius_temps if temp >= 0]\n",
    "\n",
    "print(fahrenheit_temps)  # Output: [32.0, 59.0, 77.0, 86.0, 41.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df00d538-adc6-4b41-aaac-c4030729a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.How would you write a Python function that reads a CSV file\n",
    "# and removes duplicate rows based on a specified column, saving the cleaned data back into a new CSV file?\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def remove_duplicates(input_file, output_file, column_name):\n",
    "    \"\"\"Reads a CSV file, removes duplicate rows based on a column, and saves the cleaned data.\"\"\"\n",
    "    df = pd.read_csv(input_file)  # Read the CSV file\n",
    "    df = df.drop_duplicates(subset=[column_name])  # Remove duplicates based on the specified column\n",
    "    df.to_csv(output_file, index=False)  # Save cleaned data to a new CSV file\n",
    "\n",
    "# Example usage:\n",
    "remove_duplicates(\"customers.csv\", \"cleaned_customers.csv\", \"email\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f92e14-f3cd-499e-a52e-f4e06b6e96ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
