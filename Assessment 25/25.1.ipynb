{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d31f0-1eb6-4063-9694-a233ed0a6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. In a scenario where you're building a tool that interacts with a web API,\n",
    "# you need to accept an API key, endpoint, and parameters as command-line arguments.\n",
    "# How would you implement this and ensure that the provided values are valid before making the API request?\n",
    "\n",
    "import argparse\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # Parse command-line arguments\n",
    "    parser = argparse.ArgumentParser(description=\"Interact with web APT\")\n",
    "    parser.add_argument('--api-key', required=True, help=\"API key for authentication\")\n",
    "    parser.add_argument('--endpoint', required=True, help=\"API endpoint URL\")\n",
    "    parser.add_argument('--params', nargs='*', help=\"Parameters as key-value pairs\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Validate API key (simple check for non-empty string)\n",
    "    if not args.api_key:\n",
    "        print(\"Error:API key cannot be empty.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Validate endpoint (simple check for non-empty string and starts with http/https)\n",
    "    if not args.endpoint.startswith(('http://','https://')):\n",
    "        print(\"Error: Endpoint must be valid URL starting with http:// or https://\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Parse parameters into a dictionary\n",
    "    params = {}\n",
    "    if args.params:\n",
    "        for param in args.params:\n",
    "            if '=' not in params:\n",
    "                print(f\"Error: Invalid parameter format: {param}. Expected key=value.\", file=sys.stderr)\n",
    "                sys.exit(1)\n",
    "\n",
    "            key, value = param.split('=', 1)\n",
    "            param[key] = value\n",
    "\n",
    "    # Make the API request\n",
    "    try:\n",
    "        headers = {'Authorization' : f'Bearer {args.api_key}'}\n",
    "        response = requests.get(args.endpoint, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        print(\"API Response:\", response.json())\n",
    "\n",
    "    except requests.exceptions.RequestExceptions as e:\n",
    "        print(f\"Error: Failed to make API request. {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eca039-8a01-4b2e-9130-86235dd749e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Your task is to create a command-line tool that reads a list of integers passed as arguments and computes their sum and average.\n",
    "# How would you handle potential errors, such as non-numeric values or incorrect number formats, and ensure that the program functions as expected?\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # Set up argument parser\n",
    "    parser = argparse.ArgumentParser(description=\"Compute the sum and average of a list of integers.\")\n",
    "    parser.add_argument('numbers', nargs='+', help=\"List of integers to process\")\n",
    "\n",
    "    # Parse arguments\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Validate and convert input to integers\n",
    "    try:\n",
    "        numbers = [int(num) for num in args.numbers]\n",
    "    except ValueError:\n",
    "        print(\"Error: All arguments must be valid integers.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Compute sum and average\n",
    "    total = sum(numbers)\n",
    "    average = total / len(numbers)\n",
    "\n",
    "    # Output results\n",
    "    print(f\"Sum: {total}\")\n",
    "    print(f\"Average: {average}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d8fd94d-f67b-47cb-9ff1-d0c1f85a669e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-01 12:10:00: Failed to connect to database.\n",
      "2023-10-01 12:20:00: Unable to read configuration file.\n"
     ]
    }
   ],
   "source": [
    "# 3. You are working with a log file containing system event data,  and each log entry has a timestamp, log level (INFO, WARN, ERROR), and a message.\n",
    "# How would you use regular expressions to extract all ERROR messages from the logs and  sort them by timestamp?\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Regular expression to match log entries\n",
    "log_pattern = re.compile(r'(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) (?P<level>INFO|WARN|ERROR) (?P<message>.*)')\n",
    "\n",
    "# Read the log file\n",
    "with open('logfile.txt', 'r') as file:\n",
    "    log_data = file.readlines()\n",
    "\n",
    "# Extract ERROR messages and store them with timestamps\n",
    "error_entries = []\n",
    "for line in log_data:\n",
    "    match = log_pattern.match(line)\n",
    "    if match and match.group('level') == 'ERROR':\n",
    "        timestamp = datetime.strptime(match.group('timestamp'), '%Y-%m-%d %H:%M:%S')\n",
    "        message = match.group('message')\n",
    "        error_entries.append((timestamp, message))\n",
    "\n",
    "# Sort ERROR messages by timestamp\n",
    "error_entries.sort(key=lambda x: x[0])\n",
    "\n",
    "# Output the sorted ERROR messages\n",
    "for timestamp, message in error_entries:\n",
    "    print(f\"{timestamp}: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1afb211-a24f-401b-90c5-40c323486c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n"
     ]
    }
   ],
   "source": [
    "# 4. You're tasked with writing a function that takes an array of integers and returns the indices of two numbers that add up to a specific target sum.\n",
    "# How can you improve the time complexity to O(n) while ensuring that the array is traversed only once?\n",
    "\n",
    "def two_sum(nums, target):\n",
    "    seen = {}  # Dictionary to store numbers and their indices\n",
    "    for i, num in enumerate(nums):\n",
    "        complement = target - num\n",
    "        if complement in seen:\n",
    "            return [seen[complement], i]  # Return indices\n",
    "        seen[num] = i  # Store the number and its index\n",
    "    return []  # Return empty if no pair is found\n",
    "\n",
    "\n",
    "nums = [2, 7, 11, 15]\n",
    "target = 13\n",
    "print(two_sum(nums, target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11143c92-951b-49a9-8b40-d18e33794823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. You have a large matrix representing a grid of values. You are asked to rotate this grid by 90 degrees clockwise in place.\n",
    "# What algorithm would you use to accomplish this, and how would you handle the array in a memory efficient manner?\n",
    "\n",
    "def rotate_matrix(matrix):\n",
    "    n = len(matrix)\n",
    "    \n",
    "    # Step 1: Transpose the matrix\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n",
    "    \n",
    "    # Step 2: Reverse each row\n",
    "    for i in range(n):\n",
    "        matrix[i] = matrix[i][::-1]\n",
    "\n",
    "matrix = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "]\n",
    "\n",
    "rotate_matrix(matrix)\n",
    "\n",
    "# Print the rotated matrix\n",
    "for row in matrix:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed36d0-e0b4-44dd-8bfc-ef51263dfe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extension for Non-Square Matrices:\n",
    "def rotate_non_square_matrix(matrix):\n",
    "    m = len(matrix)\n",
    "    n = len(matrix[0])\n",
    "    \n",
    "    # Create a new matrix with swapped dimensions\n",
    "    rotated = [[0] * m for _ in range(n)]\n",
    "    \n",
    "    # Populate the new matrix\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            rotated[j][m - 1 - i] = matrix[i][j]\n",
    "    \n",
    "    return rotated\n",
    "\n",
    "matrix = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "]\n",
    "\n",
    "rotated = rotate_non_square_matrix(matrix)\n",
    "\n",
    "# Print the rotated matrix\n",
    "for row in rotated:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af0e04f4-1ead-4803-8642-7cbea2a33a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered URLs (visited at least 2 times):\n",
      "https://example.com/page1: 3 times\n",
      "https://example.com/page2: 2 times\n"
     ]
    }
   ],
   "source": [
    "# 6. In a large web scraping project, you need to track the frequency of visited URLs and filter out URLs that are visited less than a certain number of times.\n",
    "# How would you leverage collections.defaultdict to accomplish this efficiently?\n",
    "# Provide an example of when this might be useful in practice.\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize a defaultdict to track URL frequencies\n",
    "url_frequencies = defaultdict(int)\n",
    "\n",
    "# List of visited URLs \n",
    "visited_urls = [\n",
    "    \"https://example.com/page1\",\n",
    "    \"https://example.com/page2\",\n",
    "    \"https://example.com/page1\",\n",
    "    \"https://example.com/page3\",\n",
    "    \"https://example.com/page2\",\n",
    "    \"https://example.com/page1\",\n",
    "]\n",
    "\n",
    "# Count the frequency of each URL\n",
    "for url in visited_urls:\n",
    "    url_frequencies[url] += 1\n",
    "\n",
    "# Filter URLs visited less than a certain number of times \n",
    "threshold = 2\n",
    "filtered_urls = {url: count for url, count in url_frequencies.items() if count >= threshold}\n",
    "\n",
    "print(\"Filtered URLs (visited at least 2 times):\")\n",
    "for url, count in filtered_urls.items():\n",
    "    print(f\"{url}: {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "833b1265-b8ce-4ef8-bfe4-eb65d1a1ead7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users (1, 3) share preferences: ['python', 'c']\n",
      "Users (1, 2, 4) share preferences: ['java']\n",
      "Users (2, 4) share preferences: ['sql']\n"
     ]
    }
   ],
   "source": [
    "# 7. Imagine you're working with a dataset of users, where each user has a unique ID and a list of preferences.\n",
    "# How can you efficiently group these users based on common preferences using the collections module?\n",
    "# Explain why this approach would be more optimal than other methods.\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sample dataset\n",
    "users = {\n",
    "    1: [\"python\", \"java\", \"c\"],\n",
    "    2: [\"java\", \"sql\"],\n",
    "    3: [\"python\", \"c\"],\n",
    "    4: [\"sql\", \"java\"],\n",
    "}\n",
    "\n",
    "# Step 1: Map each preference to a list of users\n",
    "preference_to_users = defaultdict(list)\n",
    "for user_id, preferences in users.items():\n",
    "    for preference in preferences:\n",
    "        preference_to_users[preference].append(user_id)\n",
    "\n",
    "# Step 2: Group users with common preferences\n",
    "# Create a dictionary to store groups of users\n",
    "user_groups = defaultdict(list)\n",
    "\n",
    "# Iterate through the preferences and group users\n",
    "for preference, user_list in preference_to_users.items():\n",
    "    # Use a tuple of user IDs as the key to represent a group\n",
    "    user_groups[tuple(sorted(user_list))].append(preference)\n",
    "\n",
    "# Output the groups\n",
    "for group, preferences in user_groups.items():\n",
    "    print(f\"Users {group} share preferences: {preferences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f24a8371-c614-4a92-b124-ec9cae82b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.In a scenario where you're analyzing web page data, you need to extract all the URLs from an HTML page stored in a text file.\n",
    "# How would you write a regular expression to capture URLs while considering variations in domain names and protocols?\n",
    "\n",
    "# https?:\\/\\/[^\\s\"']+|ftp:\\/\\/[^\\s\"']+|www\\.[^\\s\"']+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c90cb6-00db-4b6f-a838-96e79a136bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://example.com\n",
      "http://sub.example.com/path?query=param\n",
      "ftp://files.example.com\n",
      "www.example.com\n",
      "https://example.com/image.png\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regular expression to match URLs\n",
    "url_pattern = re.compile(r'https?:\\/\\/[^\\s\"\\'\\]]+|ftp:\\/\\/[^\\s\"\\'\\]]+|www\\.[^\\s\"\\'\\]]+')\n",
    "\n",
    "# Read the HTML content from a file\n",
    "with open('sample_web.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Find all URLs in the HTML content\n",
    "urls = url_pattern.findall(html_content)\n",
    "\n",
    "# Print the extracted URLs\n",
    "for url in urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b307a714-b92e-49a2-a910-c675f1c144a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Regular expression to match URLs\n",
    "url_pattern = re.compile(r'https?:\\/\\/[^\\s\"\\'\\]]+|ftp:\\/\\/[^\\s\"\\'\\]]+|www\\.[^\\s\"\\'\\]]+')\n",
    "\n",
    "# Read the HTML content from a file\n",
    "with open('sample_web.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Find all URLs in the HTML content\n",
    "urls = url_pattern.findall(html_content)\n",
    "\n",
    "# Print the extracted URLs\n",
    "for url in urls:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14bd808b-29f7-47a7-840c-5012945b8cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 5, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 9. You need to implement a system that tracks the maximum value of a sliding window of a fixed size within a stream of integers.\n",
    "# For each new number added to the stream, you must calculate the maximum value within the window that contains that number, efficiently updating the result as the window slides.\n",
    "# How would you implement this with collections.deque, and why is this method more efficient than simply iterating over the window each time?\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "def sliding_window_maximum(nums, k):\n",
    "    if not nums or k <= 0:\n",
    "        return []\n",
    "    \n",
    "    # Initialize a deque\n",
    "    dq = deque()\n",
    "    result = []\n",
    "    \n",
    "    for i, num in enumerate(nums):\n",
    "        # Remove indices of elements from the back of the deque that are smaller than the current element\n",
    "        while dq and nums[dq[-1]] < num:\n",
    "            dq.pop()\n",
    "        \n",
    "        # Add the current element's index to the back of the deque\n",
    "        dq.append(i)\n",
    "        \n",
    "        # Remove the index at the front of the deque if it is outside the current window\n",
    "        if dq[0] == i - k:\n",
    "            dq.popleft()\n",
    "        \n",
    "        # If the window has reached size k, append the maximum to the result\n",
    "        if i >= k - 1:\n",
    "            result.append(nums[dq[0]])\n",
    "    \n",
    "    return result\n",
    "\n",
    "nums = [1, 3, -1, -3, 5, 3, 6, 7]\n",
    "k = 3\n",
    "print(sliding_window_maximum(nums, k))  # Output: [3, 3, 5, 5, 6, 7]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
